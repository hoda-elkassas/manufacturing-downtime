{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7oMPJm79T3c",
        "outputId": "3e70a61c-c8fe-4e80-85ad-10fcf3608a14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All four sheets loaded successfully!\n",
            "Details shape: (38, 6)\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Load Libraries and Read Data from Excel File\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the file name (must match the file name uploaded to Colab)\n",
        "excel_file = 'Manufacturing_Line_Productivity.xlsx'\n",
        "\n",
        "# Read the four sheets from the Excel file into separate DataFrames\n",
        "try:\n",
        "    df_details = pd.read_excel(excel_file, sheet_name='Line productivity')\n",
        "    df_products = pd.read_excel(excel_file, sheet_name='Products')\n",
        "    df_factors = pd.read_excel(excel_file, sheet_name='Downtime factors')\n",
        "    df_downtime = pd.read_excel(excel_file, sheet_name='Line downtime')\n",
        "\n",
        "    print(\"All four sheets loaded successfully!\")\n",
        "    print(f\"Details shape: {df_details.shape}\")\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"Error reading sheets: {e}. Please ensure sheet names are exact.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Cleaning and Preprocessing Batch Details (df_details) - FINAL ROBUST TIME FIX\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "# Reload df_details to ensure 'Date', 'Start Time', 'End Time' columns are present\n",
        "# This is necessary if the cell has been run before and these columns were dropped.\n",
        "df_details = pd.read_excel(excel_file, sheet_name='Line productivity')\n",
        "\n",
        "# Function to robustly parse time values, handling Excel floats, strings, and datetime.time objects\n",
        "def parse_time_component(value):\n",
        "    if pd.isna(value):\n",
        "        return pd.NaT\n",
        "    if isinstance(value, (int, float)): # Excel time values are often floats (fraction of a day)\n",
        "        # Convert fraction of a day to timedelta, then extract the time part\n",
        "        return (pd.Timestamp('1900-01-01') + pd.to_timedelta(value, unit='D')).time()\n",
        "    # If it's already a datetime.time object (from read_excel directly)\n",
        "    if isinstance(value, dt.time):\n",
        "        return value\n",
        "    # If it's a pandas Timestamp object, extract its time\n",
        "    if isinstance(value, pd.Timestamp):\n",
        "        return value.time()\n",
        "    # Otherwise, treat as a string and try to parse it\n",
        "    try:\n",
        "        # Use pandas to_datetime for string parsing, then get the time\n",
        "        return pd.to_datetime(str(value), errors='coerce').time()\n",
        "    except AttributeError: # .time() fails if pd.to_datetime(str(value), errors='coerce') results in NaT\n",
        "        return pd.NaT\n",
        "    except Exception: # Catch any other unexpected errors during parsing\n",
        "        return pd.NaT\n",
        "\n",
        "# 1. Prepare Product and Factor tables (renaming for merging)\n",
        "df_factors = df_factors.rename(columns={'Factor': 'Factor ID', 'Description': 'Factor Description', 'Operator Error': 'Is Operator Error'})\n",
        "df_products = df_products.rename(columns={'Min batch time': 'Min Batch Duration (min)'})\n",
        "df_factors['Factor ID'] = df_factors['Factor ID'].astype(int)\n",
        "\n",
        "# 2. Create Start and End Timestamps (Using Timedelta for Robustness and CLEANUP)\n",
        "# Convert 'Date' column to datetime type\n",
        "df_details['Date'] = pd.to_datetime(df_details['Date'], format='%Y-%m-%d')\n",
        "\n",
        "# Apply the robust parsing function to 'Start Time' and 'End Time' columns\n",
        "df_details['Clean Start Time'] = df_details['Start Time'].apply(parse_time_component)\n",
        "df_details['Clean End Time'] = df_details['End Time'].apply(parse_time_component)\n",
        "\n",
        "# Convert the CLEANED Time (datetime.time objects or NaT) to Timedelta.\n",
        "# astype(str) converts datetime.time objects to 'HH:MM:SS' strings, which pd.to_timedelta can parse.\n",
        "# If 'Clean Start Time' contains NaT, .astype(str) yields 'NaT', and pd.to_timedelta('NaT', errors='coerce') yields NaT.\n",
        "df_details['Time Delta Start'] = pd.to_timedelta(df_details['Clean Start Time'].astype(str), errors='coerce')\n",
        "df_details['Time Delta End'] = pd.to_timedelta(df_details['Clean End Time'].astype(str), errors='coerce')\n",
        "\n",
        "# Combine the Date (which is at 00:00:00) with the Time Delta\n",
        "df_details['Start Timestamp'] = df_details['Date'] + df_details['Time Delta Start']\n",
        "df_details['End Timestamp'] = df_details['Date'] + df_details['Time Delta End']\n",
        "\n",
        "# 3. Correct for overnight batches (Critical step for time accuracy)\n",
        "# If End Timestamp is chronologically before Start Timestamp, it means it ended the next calendar day\n",
        "mask_overnight = df_details['End Timestamp'] < df_details['Start Timestamp']\n",
        "df_details.loc[mask_overnight, 'End Timestamp'] += pd.Timedelta(days=1)\n",
        "\n",
        "# 4. Calculate the Actual Batch Duration (in minutes)\n",
        "df_details['Actual Duration (min)'] = (df_details['End Timestamp'] - df_details['Start Timestamp']).dt.total_seconds() / 60\n",
        "\n",
        "# Clean up unnecessary original and temporary columns\n",
        "df_details = df_details.drop(columns=['Date', 'Start Time', 'End Time', 'Clean Start Time', 'Clean End Time', 'Time Delta Start', 'Time Delta End'])\n",
        "print(\"Batch Details cleaned and Timestamps/Duration calculated using the robust Timedelta method.\")\n",
        "print(df_details[['Batch', 'Actual Duration (min)']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjaITlBX-rFc",
        "outputId": "43bfe08b-783f-4bd7-86d8-e25005ead7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Details cleaned and Timestamps/Duration calculated using the robust Timedelta method.\n",
            "    Batch  Actual Duration (min)\n",
            "0  422111                  135.0\n",
            "1  422112                  100.0\n",
            "2  422113                  110.0\n",
            "3  422114                  100.0\n",
            "4  422115                   84.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Transforming Downtime Data (df_downtime) from Wide to Long Format\n",
        "\n",
        "# Reload df_downtime with header=1 to correctly interpret the second row as headers.\n",
        "# This ensures 'Batch' and factor IDs become proper column names.\n",
        "df_downtime = pd.read_excel(excel_file, sheet_name='Line downtime', header=1)\n",
        "\n",
        "# Convert numeric column names (which might be floats like 1.0, 2.0) to integers\n",
        "# This loop handles cases where column names are ints or floats representing ints.\n",
        "new_columns = []\n",
        "for col in df_downtime.columns:\n",
        "    try:\n",
        "        # Check if column name is an integer or a float that represents an integer\n",
        "        if pd.notna(col) and isinstance(col, (int, float)) and float(col).is_integer():\n",
        "            new_columns.append(int(col))\n",
        "        else:\n",
        "            new_columns.append(col)\n",
        "    except (ValueError, TypeError): # Catch if col is not numeric\n",
        "        new_columns.append(col)\n",
        "df_downtime.columns = new_columns\n",
        "\n",
        "\n",
        "# Identify factor columns. These are now expected to be integer type column names.\n",
        "factor_columns = [col for col in df_downtime.columns if isinstance(col, int)]\n",
        "\n",
        "# Melt the DataFrame to convert to Long Format\n",
        "df_downtime_long = df_downtime.melt(\n",
        "    id_vars=['Batch'],\n",
        "    value_vars=factor_columns,\n",
        "    var_name='Factor ID',\n",
        "    value_name='Downtime Duration (min)'\n",
        ")\n",
        "\n",
        "# Clean: Drop rows where Downtime Duration is NaN (meaning no downtime for that factor)\n",
        "df_downtime_long = df_downtime_long.dropna(subset=['Downtime Duration (min)'])\n",
        "\n",
        "# Ensure Factor ID and Duration are correct integer types\n",
        "df_downtime_long['Factor ID'] = df_downtime_long['Factor ID'].astype(int)\n",
        "df_downtime_long['Downtime Duration (min)'] = df_downtime_long['Downtime Duration (min)'].astype(int)\n",
        "\n",
        "print(\"Downtime records converted to Long format and cleaned.\")\n",
        "print(df_downtime_long.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3ThPlY6AlzM",
        "outputId": "52950e7d-c8b0-4275-d9fb-ae5771482021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downtime records converted to Long format and cleaned.\n",
            "     Batch  Factor ID  Downtime Duration (min)\n",
            "38  422111          2                       60\n",
            "39  422112          2                       20\n",
            "40  422113          2                       50\n",
            "44  422117          2                       10\n",
            "57  422130          2                       20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Building the Final Data Model (Merging) and Feature Engineering\n",
        "\n",
        "# 1. Merge Downtime (Long) with Factors\n",
        "df_model = pd.merge(df_downtime_long, df_factors, on='Factor ID', how='left')\n",
        "\n",
        "# 2. Merge with Batch Details (using df_details cleaned in Cell 2)\n",
        "df_model = pd.merge(df_model, df_details, on='Batch', how='left')\n",
        "\n",
        "# 3. Merge with Product Details\n",
        "df_model = pd.merge(df_model, df_products, on='Product', how='left')\n",
        "\n",
        "# Feature Engineering 1: Calculate Total Downtime per Batch\n",
        "# Grouping by 'Batch' to get the total downtime\n",
        "df_downtime_summary = df_model.groupby('Batch')['Downtime Duration (min)'].sum().reset_index().rename(\n",
        "    columns={'Downtime Duration (min)': 'Total Downtime (min)'}\n",
        ")\n",
        "df_model = pd.merge(df_model, df_downtime_summary, on='Batch', how='left')\n",
        "\n",
        "# Feature Engineering 2: Calculate Deviation from Minimum Required Time\n",
        "df_model['Duration Deviation (min)'] = df_model['Actual Duration (min)'] - df_model['Min Batch Duration (min)']\n",
        "\n",
        "# Feature Engineering 3: Operator ID Encoding (for ML models)\n",
        "# Converting Operator names to numerical IDs\n",
        "df_model['Operator_ID'] = df_model['Operator'].astype('category').cat.codes\n",
        "\n",
        "# Final Cleaned Dataset (Remove duplicates and select final columns)\n",
        "df_cleaned_dataset = df_model.drop_duplicates().sort_values(by=['Batch', 'Factor ID']).reset_index(drop=True)\n",
        "\n",
        "# Select and reorder final columns for clarity and modeling readiness\n",
        "final_columns = [\n",
        "    'Batch', 'Product', 'Flavor', 'Size',\n",
        "    'Operator', 'Operator_ID', 'Start Timestamp', 'End Timestamp',\n",
        "    'Min Batch Duration (min)', 'Actual Duration (min)', 'Duration Deviation (min)',\n",
        "    'Total Downtime (min)', 'Factor ID', 'Factor Description',\n",
        "    'Downtime Duration (min)', 'Is Operator Error'\n",
        "]\n",
        "\n",
        "df_cleaned_dataset = df_cleaned_dataset[final_columns]\n",
        "print(\"Final Data Model built successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UKKmASaBKwj",
        "outputId": "797a3eda-a271-4a13-f7e1-3eb7faf9be8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Data Model built successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Final Quality Check and Saving Results\n",
        "\n",
        "# Quality Check: Identify batches where Total Downtime > Actual Duration (Illogical data)\n",
        "invalid_batches = df_cleaned_dataset[df_cleaned_dataset['Actual Duration (min)'] < df_cleaned_dataset['Total Downtime (min)']].drop_duplicates(subset=['Batch'])\n",
        "\n",
        "if not invalid_batches.empty:\n",
        "    print(f\"\\n!! WARNING: {len(invalid_batches)} batches have Total Downtime > Actual Duration. These require investigation or removal before ML training.\")\n",
        "    print(invalid_batches[['Batch', 'Actual Duration (min)', 'Total Downtime (min)']].to_markdown(index=False))\n",
        "else:\n",
        "    print(\"\\nData Quality Check Passed (No batches found with Total Downtime > Actual Duration).\")\n",
        "\n",
        "print(f\"\\nCleaned Dataset Shape: {df_cleaned_dataset.shape}\")\n",
        "print(\"\\n--- First 5 rows of the Cleaned Dataset ---\")\n",
        "# Print first 5 rows\n",
        "print(df_cleaned_dataset.head(5).to_markdown(index=False))\n",
        "\n",
        "# DELIVERABLE: Save the final cleaned dataset\n",
        "df_cleaned_dataset.to_csv('cleaned_productivity_data.csv', index=False)\n",
        "print(\"\\nCleaned dataset saved as 'cleaned_productivity_data.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwMPpKEkBbML",
        "outputId": "b4457ea2-59e9-4835-bb1d-e23f7aa8ab82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Quality Check Passed (No batches found with Total Downtime > Actual Duration).\n",
            "\n",
            "Cleaned Dataset Shape: (61, 16)\n",
            "\n",
            "--- First 5 rows of the Cleaned Dataset ---\n",
            "|   Batch | Product   | Flavor     | Size   | Operator   |   Operator_ID | Start Timestamp     | End Timestamp       |   Min Batch Duration (min) |   Actual Duration (min) |   Duration Deviation (min) |   Total Downtime (min) |   Factor ID | Factor Description   |   Downtime Duration (min) | Is Operator Error   |\n",
            "|--------:|:----------|:-----------|:-------|:-----------|--------------:|:--------------------|:--------------------|---------------------------:|------------------------:|---------------------------:|-----------------------:|------------:|:---------------------|--------------------------:|:--------------------|\n",
            "|  422111 | OR-600    | Orange     | 600 ml | Mac        |             3 | 2024-08-29 11:50:00 | 2024-08-29 14:05:00 |                         60 |                     135 |                         75 |                     75 |           2 | Batch change         |                        60 | Yes                 |\n",
            "|  422111 | OR-600    | Orange     | 600 ml | Mac        |             3 | 2024-08-29 11:50:00 | 2024-08-29 14:05:00 |                         60 |                     135 |                         75 |                     75 |           7 | Machine failure      |                        15 | No                  |\n",
            "|  422112 | LE-600    | Lemon lime | 600 ml | Mac        |             3 | 2024-08-29 14:05:00 | 2024-08-29 15:45:00 |                         60 |                     100 |                         40 |                     40 |           2 | Batch change         |                        20 | Yes                 |\n",
            "|  422112 | LE-600    | Lemon lime | 600 ml | Mac        |             3 | 2024-08-29 14:05:00 | 2024-08-29 15:45:00 |                         60 |                     100 |                         40 |                     40 |           8 | Batch coding error   |                        20 | Yes                 |\n",
            "|  422113 | LE-600    | Lemon lime | 600 ml | Mac        |             3 | 2024-08-29 15:45:00 | 2024-08-29 17:35:00 |                         60 |                     110 |                         50 |                     50 |           2 | Batch change         |                        50 | Yes                 |\n",
            "\n",
            "Cleaned dataset saved as 'cleaned_productivity_data.csv'.\n"
          ]
        }
      ]
    }
  ]
}